# -*- coding: utf-8 -*-
"""weatherClasifikasi-MuhamadGatotSupiadin

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JsFkDI7hCG_cIK80WIxJHcdk_Mw5937v

# **Muhamad Gatot Supiadin**
## M183X0343 | M01 - Pengembangan Machine Learning dan Front End Web
## Universitas Amikom Yogyakarta , Sleman Yogyakarta

**Import Library**
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import zipfile, os
import shutil
import PIL
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from google.colab import files

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d jehanbhathena/weather-dataset

!unzip '/content/weather-dataset.zip'

def list_files(path):
  files_num = 0
  for root, dirs, files in os.walk(path):
    level = root.replace(path, '').count(os.sep)
    indent = ' ' * 2 * (level)
    files_num += len(files)
    print('{}{}/ {}'.format(indent, os.path.basename(root), (str(len(files)) + ' images' if len(files) > 0 else '')))
  
  return files_num

base_dir = '/content/dataset'
list_files(base_dir)

!rm -rf '/content/dataset/lightning'
!rm -rf '/content/dataset/hail'
!rm -rf '/content/dataset/sandstorm'
!rm -rf '/content/dataset/rainbow'
!rm -rf '/content/dataset/glaze'
!rm -rf '/content/dataset/frost'
!rm -rf '/content/dataset/rain'

def read_files(path):
  image_files = []
  for dirname, dirnames, filenames in os.walk(path):
    for filename in filenames:
      image_files.append(os.path.join(dirname, filename))
  
  return image_files

full_directory = read_files(base_dir)
image_sizes = []
for file in full_directory:
  image = PIL.Image.open(file)
  width, height = image.size
  image_sizes.append(f'{width}x{height}')

unique_sizes = set(image_sizes)

print(f'Image size list (first 15 unique size): \n{list(unique_sizes)[:15]}')

train_dir = os.path.join(base_dir, 'train')
valid_dir = os.path.join(base_dir, 'valid')

fogsmog_dir = os.path.join(base_dir, 'fogsmog')
dew_dir = os.path.join(base_dir, 'dew')
rime_dir = os.path.join(base_dir, 'rime')
snow_dir = os.path.join(base_dir, 'snow')

os.mkdir(train_dir)
os.mkdir(valid_dir)

fogsmog_train = os.path.join(train_dir, 'fogsmog')
dew_train = os.path.join(train_dir, 'dew')
rime_train = os.path.join(train_dir, 'rime')
snow_train = os.path.join(train_dir, 'snow')

fogsmog_val = os.path.join(valid_dir, 'fogsmog')
dew_val = os.path.join(valid_dir, 'dew')
rime_val = os.path.join(valid_dir, 'rime')
snow_val = os.path.join(valid_dir, 'snow')

os.mkdir(fogsmog_train)
os.mkdir(dew_train)
os.mkdir(rime_train)
os.mkdir(snow_train)

os.mkdir(fogsmog_val)
os.mkdir(dew_val)
os.mkdir(rime_val)
os.mkdir(snow_val)

from sklearn.model_selection import train_test_split

fogsmog_train_dir, fogsmog_val_dir = train_test_split(os.listdir(fogsmog_dir), test_size=0.20)
dew_train_dir, dew_val_dir = train_test_split(os.listdir(dew_dir), test_size=0.20)
rime_train_dir, rime_val_dir = train_test_split(os.listdir(rime_dir), test_size=0.20)
snow_train_dir, snow_val_dir = train_test_split(os.listdir(snow_dir), test_size=0.20)

for file in fogsmog_train_dir:
  shutil.copy(os.path.join(fogsmog_dir, file), os.path.join(fogsmog_train, file))
for file in dew_train_dir:
  shutil.copy(os.path.join(dew_dir, file), os.path.join(dew_train, file))
for file in rime_train_dir:
  shutil.copy(os.path.join(rime_dir, file), os.path.join(rime_train, file))
for file in snow_train_dir:
  shutil.copy(os.path.join(snow_dir, file), os.path.join(snow_train, file))
for file in fogsmog_val_dir:
  shutil.copy(os.path.join(fogsmog_dir, file), os.path.join(fogsmog_val, file))
for file in dew_val_dir:
  shutil.copy(os.path.join(dew_dir, file), os.path.join(dew_val, file))
for file in rime_val_dir:
  shutil.copy(os.path.join(rime_dir, file), os.path.join(rime_val, file))
for file in snow_val_dir:
  shutil.copy(os.path.join(snow_dir, file), os.path.join(snow_val, file))

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 20,
    horizontal_flip = True,
    shear_range = 0.2,
    fill_mode = 'nearest'
)

test_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 20,
    horizontal_flip = True,
    vertical_flip = True,
    shear_range = 0.2,
    fill_mode = 'nearest'
)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size = (100,100),
    batch_size = 4,
    class_mode = 'categorical' 
)

valid_generator = test_datagen.flow_from_directory(
    valid_dir,
    target_size = (100,100),
    batch_size = 4,
    class_mode = 'categorical'
)

class WetCallbacks(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>=0.90) and (logs.get('val_accuracy')>=0.90):
      print('\nAkurasi train dan test telah mencapai 90% !')
      self.model.stop_training = True
callbacks = WetCallbacks()

IMG_SHAPE = (100,100, 3)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(5, (3, 3), activation='relu', input_shape=(IMG_SHAPE)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_SHAPE)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(IMG_SHAPE)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=(IMG_SHAPE)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(120, activation='relu'),
    tf.keras.layers.Dense(83, activation='relu'),
    tf.keras.layers.Dense(4, activation='softmax')
])

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])


model.summary()

epoch = 150
history = model.fit(
    train_generator,
    steps_per_epoch = 30,
    epochs = epoch,
    validation_data = valid_generator,
    validation_steps = 20,
    batch_size = 128,
    verbose = 2,
    callbacks = [callbacks]
)

"""**Plotting Model**"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Model Accuracy')
plt.legend(loc=0)
plt.figure()

plt.show()

plt.plot(epochs, loss, 'r', label='Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Loss Model')
plt.legend(loc=0)
plt.figure()

plt.show()

"""**Convert Model To tflite**"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)

tflite = converter.convert()

with tf.io.gfile.GFile('weather_model.tflite', 'wb') as f:
  f.write(tflite)